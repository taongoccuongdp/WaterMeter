{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Setup\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Activation, Bidirectional, Dropout, LSTM, MaxPooling2D\n",
    "from keras import applications\n",
    "from keras.layers import Reshape, Lambda, BatchNormalization\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam, Adadelta\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import json\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import itertools\n",
    "import random\n",
    "import editdistance\n",
    "random.seed(2020)\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define\n",
    "SIZE = 100, 32\n",
    "ADAM_LR = 0.001\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 3\n",
    "FINETUNE = False\n",
    "DOWNSAMPLE_FACTOR = 32\n",
    "LETTERS = \"0123456789ABCDEFGHIJ,\"\n",
    "NUM_CLASS = len(LETTERS) + 1\n",
    "MAX_LENGTH = 9\n",
    "IMG_PATH = r\"Dataset/easy_samples\"\n",
    "LABEL_PATH = r\"Dataset/easy_samples.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modify pooling layer\n",
    "def maxpooling(base_model):\n",
    "    model = Sequential(name='vgg16')\n",
    "    for layer in base_model.layers[:-1]:\n",
    "        if 'pool' in layer.name:\n",
    "            pooling_layer = MaxPooling2D(pool_size=(2, 2), name=layer.name)\n",
    "            model.add(pooling_layer)\n",
    "        else:\n",
    "            model.add(layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_labels(text):\n",
    "    return list(map(lambda x: LETTERS.index(x), text))\n",
    "def labels_to_text(labels):\n",
    "    return ''.join(list(map(lambda x: LETTERS[x] if x<len(letters) else \"\", labels)))\n",
    "def ctc_lambda(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    def __init__(self,img_dirpath, labels_path, img_w, img_h,idxs, training = True, n_eraser=5):\n",
    "        self.img_w = img_w\n",
    "        self.img_h = img_h\n",
    "        self.idxs = idxs\n",
    "        self.img_dirpath = img_dirpath\n",
    "        self.labels = json.load(open(labels_path)) if labels_path != None else None\n",
    "        self.img_dir = os.listdir(self.img_dirpath)\n",
    "        if self.idxs is not None:\n",
    "            self.img_dir = [self.img_dir[idx] for idx in self.idxs]\n",
    "        self.n = len(self.img_dir)\n",
    "        self.indexes = list(range(self.n))\n",
    "        self.cur_index = 0\n",
    "        self.imgs = np.zeros((self.n, self.img_h, self.img_w, 3), dtype=np.float16)\n",
    "        self.training = training\n",
    "        self.texts = []\n",
    "    def build_data(self):\n",
    "        print(self.n, \"Image Loading....\",  self.img_dirpath)\n",
    "        for i, img_file in enumerate(self.img_dir):\n",
    "            img = image.load_img(self.img_dirpath + img_file, target_size = SIZE[::-1])\n",
    "            img = image.img_to_array(img)\n",
    "            img = preprocess_input(img).astype(np.float16)\n",
    "            self.imgs[i] = img\n",
    "            if self.labels != None:\n",
    "                self.texts.append(self.labels[img_file])\n",
    "            else:\n",
    "                self.texts.append('')\n",
    "        print(\"Done!\")\n",
    "    def next_sample(self):\n",
    "        self.cur_index += 1\n",
    "        if self.cur_index > self.n:\n",
    "            self.cur_index = 0\n",
    "            random.shuffle(self.indexes)\n",
    "        return self.imgs[self.indexes[self.cur_index]].astype(np.float32), self.texts[self.indexes[self.cur_index]]\n",
    "    def next_batch(self):\n",
    "        while True:\n",
    "            X_data = np.zeros([BATCH_SIZE, self.img_w, self.img_h, 3], dtype=np.float32)\n",
    "            Y_data = np.zeros([BATCH_SIZE, MAX_LENGTH], dtype=np.float32)   \n",
    "            input_length= np.ones((BATCH_SIZE, 1), dtype=np.float32) * (self.img_w//DOWNSAMPLE_FACTOR - 2)\n",
    "            label_length = np.zeros((BATCH_SIZE, 1), dtype=np.float32)\n",
    "            for i in range(BATCH_SIZE):\n",
    "                img, text = self.next_sample()\n",
    "                img = img.transpose((1, 0, 2))\n",
    "                X_data[i] = img\n",
    "                Y_data[i, :len(text)] = text_to_labels(text)\n",
    "                label_length[i] = len(text)\n",
    "            inputs={\n",
    "                'the_inputs': X_data,\n",
    "                'the_labels': Y_data,\n",
    "                'input_length': input_length,\n",
    "                'label_length': label_length\n",
    "            }\n",
    "            outputs={'ctc': np.zeros([BATCH_SIZE])}\n",
    "            yield (inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build model\n",
    "def build_model(input_shape, training, finetune):\n",
    "    #build cnn layer\n",
    "    inputs = Input(name=\"the_inputs\", shape=input_shape, dtype='float32')\n",
    "    base_model = applications.VGG16(weights='imagenet', include_top=False)\n",
    "    base_model = maxpooling(base_model)\n",
    "    inner = base_model(inputs)\n",
    "    inner = Reshape(target_shape=(int(inner.shape[1]), -1), name='reshape')(inner)\n",
    "    inner = Dense(512, activation='relu', kernel_initializer='he_normal', name='dense1')(inner) \n",
    "    inner = Dropout(0.25)(inner) \n",
    "    lstm1 = Bidirectional(LSTM(512, return_sequences=True, kernel_initializer='he_normal', name='lstm1', dropout=0.25, recurrent_dropout=0.25))(inner)\n",
    "    lstm2 = Bidirectional(LSTM(512, return_sequences=True, kernel_initializer='he_normal', name='lstm1', dropout=0.25, recurrent_dropout=0.25))(lstm1)\n",
    "    y_pred = Dense(NUM_CLASS, activation='softmax', kernel_initializer='he_normal')(lstm2)\n",
    "    labels= Input(name='the_labels', shape=[LABEL_LEN], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "    loss = Lambda(ctc_lambda, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = finetune\n",
    "    y_func = K.function([inputs], [y_pred])\n",
    "    if training:\n",
    "        Model(inputs=[inputs, labels, input_length, label_length], outputs=loss).summary()\n",
    "        return Model(inputs=[inputs, labels, input_length, label_length], outputs=loss), y_func\n",
    "    else:\n",
    "        return Model(inputs=[inputs], outputs = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\taong\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\taong\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_inputs (InputLayer)         (None, 100, 32, 3)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg16 (Sequential)              multiple             14714688    the_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 6, 1024)      0           vgg16[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 6, 512)       524800      reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 6, 512)       0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 6, 1024)      4198400     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 6, 1024)      6295552     bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 6, 22)        22550       bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "the_labels (InputLayer)         (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc (Lambda)                    (None, 1)            0           dense_1[0][0]                    \n",
      "                                                                 the_labels[0][0]                 \n",
      "                                                                 input_length[0][0]               \n",
      "                                                                 label_length[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 25,755,990\n",
      "Trainable params: 11,041,302\n",
      "Non-trainable params: 14,714,688\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Test model\n",
    "model, y_func = build_model((*SIZE, 3), training=True, finetune=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training with kfold\n",
    "def train_kfold(idx, kfold, imgpath, labelpath, finetune):\n",
    "    sess = tf.Session()\n",
    "    K.set_session(sess)\n",
    "    model, y_func = build_model((*SIZE, 3), training=True, finetune=finetune)\n",
    "    ada = Adam(lr = LR)\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=ada)\n",
    "    train_idx, valid_idx = kfold[idx]\n",
    "    train_generator = DataGenerator(imgpath, labelpath, *SIZE, train_idx, True)\n",
    "    train_generator.build_data()\n",
    "    valid_generator = DataGenerator(imgpath, labelpath, *SIZE, train_idx, False)\n",
    "    valid_generator.build_data()\n",
    "    weight_path = 'model/pre_weight_%d.h5'%idx\n",
    "    ckp = ModelCheckpoint(weight_path, monitor = 'val_loss', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "    earlystop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min')\n",
    "    if finetune:\n",
    "        print('load pretrain model')\n",
    "        model.load_weights(weight_path)\n",
    "    model.fit_generator(generator=train_generator.next_batch(),\n",
    "                       steps_per_epoch=int(len(train_idx)/BATCH_SIZE),\n",
    "                        epochs=EPOCHS,\n",
    "                        callbacks=[ckp, earlystop],\n",
    "                        validation_data = valid_generator.next_batch(),\n",
    "                        validation_steps=int(len(valid_idx)/BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainning\n",
    "def train():\n",
    "    nsplits = 5\n",
    "    nfiles = np.arange(len(os.listdir(IMG_PATH)))\n",
    "    kfold = list(KFold(nsplits, random_state=2020).split(nfiles))\n",
    "    for idx in range(nsplits):\n",
    "        train_kfold(idx, kfold, IMG_PATH, LABEL_PATH, finetune=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
